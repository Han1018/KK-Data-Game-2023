{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import (\n",
    "    TransformerEncoder,\n",
    "    TransformerEncoderLayer,\n",
    "    TransformerDecoder,\n",
    "    TransformerDecoderLayer,\n",
    ")\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn import Transformer\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "embedding_num = 29\n",
    "embedding_dim = 256\n",
    "num_layers = 8\n",
    "num_heads = 8\n",
    "ff_dim = 1024\n",
    "dropout = 0.1\n",
    "\n",
    "sos = 27\n",
    "eos = 28\n",
    "pad = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATAPATH = \"/home/zonghan/Documents/Courses/DL/DL_Lab3/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bleu-4 score function\n",
    "def bleu4_score(output, reference):\n",
    "    cc = SmoothingFunction()\n",
    "    if len(reference) == 3:\n",
    "        weights = (0.33, 0.33, 0.33)\n",
    "    else:\n",
    "        weights = (0.25, 0.25, 0.25, 0.25)\n",
    "    return sentence_bleu(\n",
    "        [reference], output, weights=weights, smoothing_function=cc.method1\n",
    "    )\n",
    "\n",
    "\n",
    "def metrics(pred: list, target: list) -> float:\n",
    "    \"\"\"\n",
    "    pred: list of strings\n",
    "    target: list of strings\n",
    "\n",
    "    return: accuracy(%)\n",
    "    \"\"\"\n",
    "    if len(pred) != len(target):\n",
    "        raise ValueError(\"length of pred and target must be the same\")\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == target[i]:\n",
    "            correct += 1\n",
    "    return correct / len(pred) * 100\n",
    "\n",
    "\n",
    "class index2char:\n",
    "    def __init__(self, root, tokenizer=None):\n",
    "        if tokenizer is None:\n",
    "            with open(root + \"tokenizer.yaml\", \"r\") as f:\n",
    "                self.tokenizer = yaml.load(f, Loader=yaml.CLoader)\n",
    "        else:\n",
    "            self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, indices: list, without_token=True):\n",
    "        if type(indices) == Tensor:\n",
    "            indices = indices.tolist()\n",
    "        result = \"\".join([self.tokenizer[\"index_2_char\"][i] for i in indices])\n",
    "        if without_token:\n",
    "            result = result.split(\"[eos]\")[0]\n",
    "            result = (\n",
    "                result.replace(\"[sos]\", \"\").replace(\"[eos]\", \"\").replace(\"[pad]\", \"\")\n",
    "            )\n",
    "        return result\n",
    "\n",
    "    def char2index(self, text):\n",
    "        # Convert a string to a list of indices\n",
    "        indices = [self.tokenizer[\"char_2_index\"].get(char) for char in text]\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellCorrectionDataset(Dataset):\n",
    "    def __init__(self, root, split: str = \"train\", tokenizer=None, padding: int = 0):\n",
    "        super(SpellCorrectionDataset, self).__init__()\n",
    "\n",
    "        self.tokenizer = index2char(root, tokenizer=tokenizer)\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "        # Load your JSON data from a file\n",
    "        with open(root + split + \".json\", \"r\") as f:\n",
    "            jsonData = json.load(f)\n",
    "\n",
    "        # Torkenize the JSON data and add the sos, eos\n",
    "        for dict in jsonData:\n",
    "            torkenized_target = self.tokenize(dict[\"target\"])\n",
    "            target = (\n",
    "                [sos]\n",
    "                + torkenized_target\n",
    "                + [eos]\n",
    "                + [pad] * (padding - len(torkenized_target) - 2)\n",
    "            )\n",
    "            inputWords = dict[\"input\"]\n",
    "\n",
    "            for word in inputWords:\n",
    "                torkenized_input = self.tokenize(word)\n",
    "                input = (\n",
    "                    [sos]\n",
    "                    + torkenized_input\n",
    "                    + [eos]\n",
    "                    + [pad] * (padding - len(torkenized_input) - 2)\n",
    "                )\n",
    "                self.inputs.append(input)\n",
    "                self.targets.append(target)\n",
    "\n",
    "        # Convert the list to a PyTorch tensor\n",
    "        self.inputs = torch.tensor(self.inputs)\n",
    "        self.targets = torch.tensor(self.targets)\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        # tokenize your text here\n",
    "        # ex: \"data\" -> [4, 1, 20, 1]\n",
    "        return self.tokenizer.char2index(text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the data by index here\n",
    "        input_ids = self.inputs[index]\n",
    "        target_ids = self.targets[index]\n",
    "\n",
    "        return input_ids, target_ids\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        dropout: float = 0.1,\n",
    "        max_len: int = 5000,\n",
    "        batch_first: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.batch_first:\n",
    "            x = x.transpose(0, 1)\n",
    "            x = x + self.pe[: x.size(0)]\n",
    "            return self.dropout(x.transpose(0, 1))\n",
    "        else:\n",
    "            x = x + self.pe[: x.size(0)]\n",
    "            return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length=100\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.tok_embedding = nn.Embedding(num_emb, hid_dim, padding_idx=pad)\n",
    "        self.pos_embedding = PositionalEncoding(\n",
    "            hid_dim, dropout, max_len=max_length, batch_first=True\n",
    "        )\n",
    "        self.layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hid_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoders = nn.TransformerEncoder(self.layer, n_layers)\n",
    "        self.d_model = hid_dim\n",
    "\n",
    "    def forward(self, src, src_padding_mask):\n",
    "        _ = self.tok_embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_embedding(_)\n",
    "        output = self.encoders(src, src_key_padding_mask=src_padding_mask)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length=100\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tok_embedding = nn.Embedding(num_emb, hid_dim, padding_idx=pad)\n",
    "        self.pos_embedding = PositionalEncoding(\n",
    "            hid_dim, dropout, max_len=max_length, batch_first=True\n",
    "        )\n",
    "        self.layer = nn.TransformerDecoderLayer(\n",
    "            d_model=hid_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.d_model = hid_dim\n",
    "        self.decoder = nn.TransformerDecoder(self.layer, n_layers)\n",
    "        self.fc = nn.Linear(hid_dim, num_emb)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask, tgt_padding_mask, src_pad_mask):\n",
    "        _ = self.tok_embedding(tgt) * math.sqrt(self.d_model)\n",
    "        tgt = self.pos_embedding(_)\n",
    "        output = self.decoder(\n",
    "            tgt=tgt,\n",
    "            memory=memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=src_pad_mask,\n",
    "        )\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerAutoEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_emb,\n",
    "        hid_dim,\n",
    "        n_layers,\n",
    "        n_heads,\n",
    "        ff_dim,\n",
    "        dropout,\n",
    "        max_length=100,\n",
    "        encoder=None,\n",
    "    ):\n",
    "        super(TransformerAutoEncoder, self).__init__()\n",
    "        if encoder is None:\n",
    "            self.encoder = Encoder(\n",
    "                num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length\n",
    "            )\n",
    "        else:\n",
    "            self.encoder = encoder\n",
    "        self.decoder = Decoder(\n",
    "            num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_pad_mask, tgt_mask, tgt_pad_mask):\n",
    "        memory = self.encoder(src, src_pad_mask)\n",
    "        dec_out = self.decoder(tgt, memory, tgt_mask, tgt_pad_mask, src_pad_mask)\n",
    "        return dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect where the padding value is\n",
    "def gen_padding_mask(src, pad_idx):\n",
    "    # pad_mask = (src == pad_idx\n",
    "    return src.eq(pad_idx)\n",
    "\n",
    "\n",
    "# triu mask for decoder\n",
    "def gen_mask(seq):\n",
    "    seq_len = seq.size(1)\n",
    "    mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_index(pred, dim=2):\n",
    "    return pred.clone().argmax(dim=dim)\n",
    "\n",
    "\n",
    "def random_change_idx(data: torch.Tensor, prob: float = 0.2):\n",
    "    # randomly change the index of the input data\n",
    "    mask = torch.rand(data.size()) < prob\n",
    "    new_data = torch.randint_like(data, low=0, high=data.max() + 1)\n",
    "    return torch.where(mask, new_data, data)\n",
    "\n",
    "\n",
    "def random_masked(data: torch.Tensor, prob: float = 0.2, mask_idx: int = 3):\n",
    "    # randomly mask the input data\n",
    "    mask = torch.rand(data.size()) < prob\n",
    "    masked_data = torch.full_like(data, fill_value=mask_idx)\n",
    "    return torch.where(mask, masked_data, data)\n",
    "\n",
    "\n",
    "def validation(dataloader, model, device, logout=False, dataset=\"test\"):\n",
    "    pred_str_list = []\n",
    "    tgt_str_list = []\n",
    "    input_str_list = []\n",
    "    losses = []\n",
    "    bleu_scores = []\n",
    "    for src, tgt in dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        # An all pad token tensor with the same shape as tgt and the first token is <sos>\n",
    "        tgt_input = torch.full_like(tgt, fill_value=pad)\n",
    "        tgt_input[:, 0] = sos\n",
    "        for i in range(tgt.shape[1] - 1):\n",
    "            src_pad_mask = gen_padding_mask(src, pad_idx=0).to(device)\n",
    "            tgt_pad_mask = gen_padding_mask(tgt_input, pad_idx=0).to(device)\n",
    "            tgt_mask = gen_mask(tgt_input).to(device)\n",
    "            pred = model(\n",
    "                src=src,\n",
    "                tgt=tgt_input,\n",
    "                src_pad_mask=src_pad_mask,\n",
    "                tgt_mask=tgt_mask,\n",
    "                tgt_pad_mask=tgt_pad_mask,\n",
    "            )\n",
    "            pred_idx = get_index(pred)\n",
    "            tgt_input[:, i + 1] = pred_idx[:, i]\n",
    "        for i in range(tgt.shape[0]):\n",
    "            pred_str_list.append(i2c(tgt_input[i].tolist()))\n",
    "            tgt_str_list.append(i2c(tgt[i].tolist()))\n",
    "            input_str_list.append(i2c(src[i].tolist()))\n",
    "            if logout:\n",
    "                print(\"=\" * 30)\n",
    "                print(f\"input: {input_str_list[-1]}\")\n",
    "                print(f\"pred: {pred_str_list[-1]}\")\n",
    "                print(f\"target: {tgt_str_list[-1]}\")\n",
    "        loss = ce_loss(pred[:, :-1, :].permute(0, 2, 1), tgt[:, 1:])\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Calculate BLEU-4 score\n",
    "        for pred_str, tgt_str in zip(pred_str_list, tgt_str_list):\n",
    "            bleu_score = bleu4_score(pred_str, tgt_str)\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "    avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "\n",
    "    print(\n",
    "        f\"{dataset}_acc: {metrics(pred_str_list, tgt_str_list):.2f}\",\n",
    "        f\"{dataset}_loss: {avg_loss:.2f}\",\n",
    "        f\"BLEU-4: {avg_bleu_score:.4f}\",\n",
    "        end=\" | \",\n",
    "    )\n",
    "    print(f\"[pred: {pred_str_list[0]} target: {tgt_str_list[0]}]\")\n",
    "    return avg_bleu_score, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2c = index2char(DATAPATH)\n",
    "\n",
    "trainset = SpellCorrectionDataset(DATAPATH, padding=22)\n",
    "testset = SpellCorrectionDataset(DATAPATH, split=\"new_test\", padding=22)\n",
    "valset = SpellCorrectionDataset(DATAPATH, split=\"test\", padding=22)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss(ignore_index=pad)\n",
    "learning_rate = 0.00005  # Adjust this based on your problem\n",
    "# learning_rate = 0.0001\n",
    "model = TransformerAutoEncoder(\n",
    "    embedding_num, embedding_dim, num_layers, num_heads, ff_dim, dropout, max_length=22\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "test_bleu_scores = []\n",
    "validation_bleu_scores = []\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "best_bleu_score = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "for eps in range(1000):\n",
    "    # train\n",
    "    losses = []\n",
    "    model.train()\n",
    "    i_bar = tqdm(trainloader, unit=\"iter\", desc=f\"epoch{eps}\")\n",
    "    for src, tgt in i_bar:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        src_pad_mask = gen_padding_mask(src, pad_idx=0).to(device)\n",
    "        tgt_pad_mask = gen_padding_mask(tgt, pad_idx=0).to(device)\n",
    "        tgt_mask = gen_mask(tgt).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(src, tgt, src_pad_mask, tgt_mask, tgt_pad_mask)\n",
    "        loss = ce_loss(pred[:, :-1, :].permute(0, 2, 1), tgt[:, 1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        i_bar.set_postfix_str(f\"loss: {sum(losses)/len(losses):.3f}\")\n",
    "\n",
    "    # Store the average training loss for the epoch\n",
    "    train_losses.append(sum(losses) / len(losses))\n",
    "\n",
    "    # test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # print(f\"epoch: {eps}\")\n",
    "        avg_bleu_score, _ = validation(testloader, model, device, dataset=\"test\")\n",
    "        test_bleu_scores.append(avg_bleu_score)\n",
    "    # eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        avg_bleu_score, avg_loss = validation(valloader, model, device, dataset=\"vali\")\n",
    "        validation_bleu_scores.append(avg_bleu_score)\n",
    "        validation_losses.append(avg_loss)\n",
    "\n",
    "        # Check if the current BLEU score is better than the best so far\n",
    "        if avg_bleu_score > best_bleu_score:\n",
    "            best_bleu_score = avg_bleu_score\n",
    "            best_epoch = eps\n",
    "\n",
    "            # Save the model state dictionary\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                \"/home/zonghan/Documents/Courses/DL/DL_Lab3/best_model.pth\",\n",
    "            )\n",
    "\n",
    "    # Plotting the training loss and BLEU-4 scores\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(validation_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"CrossEntropy Loss\")\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(test_bleu_scores, label=\"Test BLEU-4 Score\")\n",
    "    plt.plot(validation_bleu_scores, label=\"Validation BLEU-4 Score\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"BLEU-4 Score\")\n",
    "    plt.title(\"BLEU-4 Score Curve\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"/home/zonghan/Documents/Courses/DL/DL_Lab3/result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inference(dataloader, model, device, logout=False, dataset=\"test\"):\n",
    "    pred_str_list = []\n",
    "    tgt_str_list = []\n",
    "    input_str_list = []\n",
    "    losses = []\n",
    "    bleu_scores = []\n",
    "    for src, tgt in dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        # An all pad token tensor with the same shape as tgt and the first token is <sos>\n",
    "        tgt_input = torch.full_like(tgt, fill_value=pad)\n",
    "        tgt_input[:, 0] = sos\n",
    "        for i in range(tgt.shape[1] - 1):\n",
    "            src_pad_mask = gen_padding_mask(src, pad_idx=0).to(device)\n",
    "            tgt_pad_mask = gen_padding_mask(tgt_input, pad_idx=0).to(device)\n",
    "            tgt_mask = gen_mask(tgt_input).to(device)\n",
    "            pred = model(\n",
    "                src=src,\n",
    "                tgt=tgt_input,\n",
    "                src_pad_mask=src_pad_mask,\n",
    "                tgt_mask=tgt_mask,\n",
    "                tgt_pad_mask=tgt_pad_mask,\n",
    "            )\n",
    "            pred_idx = get_index(pred)\n",
    "            tgt_input[:, i + 1] = pred_idx[:, i]\n",
    "        for i in range(tgt.shape[0]):\n",
    "            pred_str_list.append(i2c(tgt_input[i].tolist()))\n",
    "            tgt_str_list.append(i2c(tgt[i].tolist()))\n",
    "            input_str_list.append(i2c(src[i].tolist()))\n",
    "            if logout:\n",
    "                print(\"=\" * 30)\n",
    "                print(f\"input: {input_str_list[-1]}\")\n",
    "                print(f\"pred: {pred_str_list[-1]}\")\n",
    "                print(f\"target: {tgt_str_list[-1]}\")\n",
    "        loss = ce_loss(pred[:, :-1, :].permute(0, 2, 1), tgt[:, 1:])\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Calculate BLEU-4 score\n",
    "        for pred_str, tgt_str in zip(pred_str_list, tgt_str_list):\n",
    "            bleu_score = bleu4_score(pred_str, tgt_str)\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "    avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "\n",
    "    print(\n",
    "        f\"{dataset}_acc: {metrics(pred_str_list, tgt_str_list):.2f}\",\n",
    "        f\"{dataset}_loss: {avg_loss:.2f}\",\n",
    "        f\"BLEU-4: {avg_bleu_score:.4f}\",\n",
    "    )\n",
    "    for i in range(len(pred_str_list)):\n",
    "        print(\n",
    "            \"Ground Truth: %-20s || Predicted word: %-20s\"\n",
    "            % (pred_str_list[i], tgt_str_list[i])\n",
    "        )\n",
    "    return avg_bleu_score, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model weights\n",
    "model.load_state_dict(\n",
    "    torch.load(\"/home/zonghan/Documents/Courses/DL/DL_Lab3/best_model_transformer.pth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 52.00 test_loss: 4.37 BLEU-4: 0.6209\n",
      "Ground Truth: appreciate           || Predicted word: appreciate          \n",
      "Ground Truth: appreciate           || Predicted word: appreciate          \n",
      "Ground Truth: appreciate           || Predicted word: appreciate          \n",
      "Ground Truth: appreciate           || Predicted word: appreciate          \n",
      "Ground Truth: appreciate           || Predicted word: appreciate          \n",
      "Ground Truth: love                 || Predicted word: love                \n",
      "Ground Truth: cloud                || Predicted word: cold                \n",
      "Ground Truth: earths               || Predicted word: heart               \n",
      "Ground Truth: television           || Predicted word: television          \n",
      "Ground Truth: phone                || Predicted word: phone               \n",
      "Ground Truth: chap                 || Predicted word: phase               \n",
      "Ground Truth: approm               || Predicted word: poem                \n",
      "Ground Truth: tomorraw             || Predicted word: tomorrow            \n",
      "Ground Truth: perishine            || Predicted word: precision           \n",
      "Ground Truth: precision            || Predicted word: precision           \n",
      "Ground Truth: persuain             || Predicted word: precision           \n",
      "Ground Truth: presion              || Predicted word: precision           \n",
      "Ground Truth: prever               || Predicted word: prefer              \n",
      "Ground Truth: proceding            || Predicted word: prejudice           \n",
      "Ground Truth: pregid               || Predicted word: prejudice           \n",
      "Ground Truth: receiver             || Predicted word: receiver            \n",
      "Ground Truth: receiver             || Predicted word: receiver            \n",
      "Ground Truth: relieve              || Predicted word: relief              \n",
      "Ground Truth: thograte             || Predicted word: together            \n",
      "Ground Truth: curtain              || Predicted word: remittance          \n",
      "Ground Truth: deposit              || Predicted word: deposit             \n",
      "Ground Truth: depthost             || Predicted word: deposit             \n",
      "Ground Truth: pepper               || Predicted word: pepper              \n",
      "Ground Truth: preprepr             || Predicted word: pepper              \n",
      "Ground Truth: employee             || Predicted word: employee            \n",
      "Ground Truth: emplose              || Predicted word: employee            \n",
      "Ground Truth: best                 || Predicted word: best                \n",
      "Ground Truth: beast                || Predicted word: best                \n",
      "Ground Truth: sight                || Predicted word: best                \n",
      "Ground Truth: feature              || Predicted word: feature             \n",
      "Ground Truth: feature              || Predicted word: feature             \n",
      "Ground Truth: fater                || Predicted word: feature             \n",
      "Ground Truth: gross                || Predicted word: gorgeous            \n",
      "Ground Truth: gorgeous             || Predicted word: gorgeous            \n",
      "Ground Truth: curious              || Predicted word: gorgeous            \n",
      "Ground Truth: grip                 || Predicted word: grip                \n",
      "Ground Truth: heinous              || Predicted word: heinous             \n",
      "Ground Truth: purple               || Predicted word: purple              \n",
      "Ground Truth: occasional           || Predicted word: occasional          \n",
      "Ground Truth: triumph              || Predicted word: triumph             \n",
      "Ground Truth: triumph              || Predicted word: triumph             \n",
      "Ground Truth: bonefallogebrate     || Predicted word: unforgettable       \n",
      "Ground Truth: botableguant         || Predicted word: unforgettable       \n",
      "Ground Truth: visible              || Predicted word: visible             \n",
      "Ground Truth: visible              || Predicted word: visible             \n",
      "Test BLEU-4 Score: 0.6209\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # print(f\"epoch: {eps}\")\n",
    "    avg_bleu_score, _ = Inference(testloader, model, device, dataset=\"test\")\n",
    "    print(f\"Test BLEU-4 Score: {avg_bleu_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
